{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SMS Spam Classification-Latest.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x0qmpS8y5Zjl"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krystal826/Natural-Language-Processing/blob/main/SMS_Spam_Classification_Latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efyA2qjW5ZjQ"
      },
      "source": [
        "# SMS Spam Classification\n",
        "\n",
        "Natural Language Processing Using Machine Learning\n",
        "https://medium.com/analytics-vidhya/sms-spam-classifier-natural-language-processing-1751e2b324ed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRAW1qox5ZjU"
      },
      "source": [
        "#Loading the libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zITJ6wr5ZjV"
      },
      "source": [
        "# 1.0 Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "VdMLnhS95ZjV",
        "outputId": "b463bb9b-5ed5-4742-80d0-35ebe3d78aed"
      },
      "source": [
        "#Reading the csv file\n",
        "messages = pd.read_csv('SMSSpamCollection',sep='\\t',names = ['Label','Message'])\n",
        "\n",
        "#Specifying the names of the columns while reading csv file (tsv--tab separated values)\n",
        "messages.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AULWXANc5ZjW"
      },
      "source": [
        "## 2.0 Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMTX8Xp25ZjW"
      },
      "source": [
        "** There are 5572 rows and 2 columns. It means that there are 5572 messages and 2 columns named “Label” and “Message”. There are no missing values in the data. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zGvfT-V5ZjX",
        "outputId": "a69c2d70-7083-4ffc-8fd5-c6bacd8ab13e"
      },
      "source": [
        "#Info about the data\n",
        "messages.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Label    5572 non-null   object\n",
            " 1   Message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Yjv8ph5ZjY",
        "outputId": "6801883d-5b23-4eb7-cbb9-4b5d991a1a26"
      },
      "source": [
        "#Finding missing values\n",
        "messages.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label      0\n",
              "Message    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmT9ychL5ZjY",
        "outputId": "41cc09b1-daa3-4303-e5b7-bff8789cf19a"
      },
      "source": [
        "#Shape of the dataframe\n",
        "messages.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD9OaD9D5ZjZ",
        "outputId": "62c10024-6122-43df-ca6c-8b6986ca6e10"
      },
      "source": [
        "#Target variables counts\n",
        "messages['Label'].value_counts()\n",
        "\n",
        "#Data is imbalanced but for now we will continue with this"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2CSUg4l5ZjZ"
      },
      "source": [
        "## 3.0 Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dsfYW735Zja"
      },
      "source": [
        "**Calculating length of message (number of characters)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBZtVZJg5Zja"
      },
      "source": [
        "#Calculating length of message\n",
        "mes_len=0\n",
        "length=[]\n",
        "for i in range(len(messages)):\n",
        "    length.append(len(messages['Message'][i]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxOdc4Ah5Zja",
        "outputId": "34fd955b-e831-4259-8fef-f8db03a24699"
      },
      "source": [
        "length"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[111,\n",
              " 29,\n",
              " 155,\n",
              " 49,\n",
              " 61,\n",
              " 147,\n",
              " 77,\n",
              " 160,\n",
              " 157,\n",
              " 154,\n",
              " 109,\n",
              " 136,\n",
              " 155,\n",
              " 196,\n",
              " 35,\n",
              " 149,\n",
              " 26,\n",
              " 81,\n",
              " 56,\n",
              " 155,\n",
              " 41,\n",
              " 47,\n",
              " 52,\n",
              " 88,\n",
              " 57,\n",
              " 144,\n",
              " 30,\n",
              " 134,\n",
              " 75,\n",
              " 64,\n",
              " 130,\n",
              " 189,\n",
              " 29,\n",
              " 84,\n",
              " 158,\n",
              " 122,\n",
              " 47,\n",
              " 28,\n",
              " 27,\n",
              " 155,\n",
              " 82,\n",
              " 142,\n",
              " 172,\n",
              " 19,\n",
              " 72,\n",
              " 32,\n",
              " 45,\n",
              " 31,\n",
              " 67,\n",
              " 148,\n",
              " 58,\n",
              " 124,\n",
              " 80,\n",
              " 289,\n",
              " 120,\n",
              " 76,\n",
              " 161,\n",
              " 34,\n",
              " 22,\n",
              " 40,\n",
              " 108,\n",
              " 48,\n",
              " 25,\n",
              " 56,\n",
              " 110,\n",
              " 152,\n",
              " 122,\n",
              " 159,\n",
              " 78,\n",
              " 34,\n",
              " 46,\n",
              " 29,\n",
              " 45,\n",
              " 42,\n",
              " 20,\n",
              " 43,\n",
              " 73,\n",
              " 50,\n",
              " 42,\n",
              " 76,\n",
              " 22,\n",
              " 32,\n",
              " 32,\n",
              " 36,\n",
              " 14,\n",
              " 55,\n",
              " 121,\n",
              " 144,\n",
              " 42,\n",
              " 41,\n",
              " 58,\n",
              " 195,\n",
              " 141,\n",
              " 137,\n",
              " 107,\n",
              " 158,\n",
              " 33,\n",
              " 51,\n",
              " 178,\n",
              " 31,\n",
              " 57,\n",
              " 81,\n",
              " 76,\n",
              " 160,\n",
              " 183,\n",
              " 44,\n",
              " 95,\n",
              " 43,\n",
              " 82,\n",
              " 115,\n",
              " 30,\n",
              " 40,\n",
              " 31,\n",
              " 96,\n",
              " 158,\n",
              " 143,\n",
              " 156,\n",
              " 152,\n",
              " 72,\n",
              " 86,\n",
              " 144,\n",
              " 156,\n",
              " 53,\n",
              " 156,\n",
              " 52,\n",
              " 38,\n",
              " 20,\n",
              " 244,\n",
              " 22,\n",
              " 107,\n",
              " 28,\n",
              " 9,\n",
              " 39,\n",
              " 25,\n",
              " 125,\n",
              " 162,\n",
              " 38,\n",
              " 34,\n",
              " 46,\n",
              " 155,\n",
              " 85,\n",
              " 33,\n",
              " 27,\n",
              " 156,\n",
              " 42,\n",
              " 25,\n",
              " 48,\n",
              " 159,\n",
              " 84,\n",
              " 33,\n",
              " 30,\n",
              " 45,\n",
              " 59,\n",
              " 25,\n",
              " 160,\n",
              " 384,\n",
              " 28,\n",
              " 27,\n",
              " 157,\n",
              " 124,\n",
              " 145,\n",
              " 115,\n",
              " 64,\n",
              " 85,\n",
              " 152,\n",
              " 155,\n",
              " 51,\n",
              " 156,\n",
              " 74,\n",
              " 67,\n",
              " 59,\n",
              " 50,\n",
              " 94,\n",
              " 33,\n",
              " 105,\n",
              " 61,\n",
              " 65,\n",
              " 26,\n",
              " 146,\n",
              " 66,\n",
              " 126,\n",
              " 159,\n",
              " 23,\n",
              " 65,\n",
              " 24,\n",
              " 26,\n",
              " 152,\n",
              " 34,\n",
              " 147,\n",
              " 55,\n",
              " 88,\n",
              " 72,\n",
              " 185,\n",
              " 37,\n",
              " 111,\n",
              " 92,\n",
              " 28,\n",
              " 28,\n",
              " 64,\n",
              " 131,\n",
              " 40,\n",
              " 28,\n",
              " 84,\n",
              " 174,\n",
              " 24,\n",
              " 25,\n",
              " 63,\n",
              " 156,\n",
              " 28,\n",
              " 86,\n",
              " 39,\n",
              " 73,\n",
              " 26,\n",
              " 23,\n",
              " 23,\n",
              " 31,\n",
              " 58,\n",
              " 48,\n",
              " 41,\n",
              " 32,\n",
              " 159,\n",
              " 25,\n",
              " 161,\n",
              " 22,\n",
              " 119,\n",
              " 142,\n",
              " 69,\n",
              " 137,\n",
              " 30,\n",
              " 165,\n",
              " 34,\n",
              " 109,\n",
              " 37,\n",
              " 33,\n",
              " 48,\n",
              " 157,\n",
              " 50,\n",
              " 65,\n",
              " 38,\n",
              " 145,\n",
              " 145,\n",
              " 51,\n",
              " 45,\n",
              " 83,\n",
              " 155,\n",
              " 37,\n",
              " 78,\n",
              " 30,\n",
              " 31,\n",
              " 146,\n",
              " 150,\n",
              " 44,\n",
              " 179,\n",
              " 27,\n",
              " 179,\n",
              " 38,\n",
              " 97,\n",
              " 43,\n",
              " 36,\n",
              " 154,\n",
              " 72,\n",
              " 3,\n",
              " 85,\n",
              " 51,\n",
              " 121,\n",
              " 26,\n",
              " 35,\n",
              " 47,\n",
              " 159,\n",
              " 47,\n",
              " 133,\n",
              " 53,\n",
              " 147,\n",
              " 155,\n",
              " 37,\n",
              " 31,\n",
              " 8,\n",
              " 38,\n",
              " 30,\n",
              " 47,\n",
              " 56,\n",
              " 22,\n",
              " 141,\n",
              " 29,\n",
              " 7,\n",
              " 121,\n",
              " 58,\n",
              " 4,\n",
              " 148,\n",
              " 160,\n",
              " 152,\n",
              " 37,\n",
              " 55,\n",
              " 21,\n",
              " 22,\n",
              " 50,\n",
              " 159,\n",
              " 67,\n",
              " 153,\n",
              " 51,\n",
              " 67,\n",
              " 88,\n",
              " 157,\n",
              " 91,\n",
              " 24,\n",
              " 146,\n",
              " 57,\n",
              " 26,\n",
              " 71,\n",
              " 138,\n",
              " 55,\n",
              " 156,\n",
              " 133,\n",
              " 119,\n",
              " 142,\n",
              " 41,\n",
              " 26,\n",
              " 119,\n",
              " 46,\n",
              " 157,\n",
              " 23,\n",
              " 51,\n",
              " 62,\n",
              " 107,\n",
              " 157,\n",
              " 30,\n",
              " 32,\n",
              " 31,\n",
              " 79,\n",
              " 32,\n",
              " 86,\n",
              " 22,\n",
              " 76,\n",
              " 128,\n",
              " 232,\n",
              " 158,\n",
              " 45,\n",
              " 57,\n",
              " 26,\n",
              " 22,\n",
              " 41,\n",
              " 28,\n",
              " 151,\n",
              " 29,\n",
              " 34,\n",
              " 52,\n",
              " 33,\n",
              " 85,\n",
              " 31,\n",
              " 111,\n",
              " 78,\n",
              " 50,\n",
              " 63,\n",
              " 148,\n",
              " 129,\n",
              " 45,\n",
              " 202,\n",
              " 150,\n",
              " 148,\n",
              " 168,\n",
              " 85,\n",
              " 38,\n",
              " 15,\n",
              " 31,\n",
              " 88,\n",
              " 160,\n",
              " 50,\n",
              " 165,\n",
              " 129,\n",
              " 26,\n",
              " 31,\n",
              " 129,\n",
              " 34,\n",
              " 54,\n",
              " 162,\n",
              " 157,\n",
              " 23,\n",
              " 53,\n",
              " 131,\n",
              " 36,\n",
              " 143,\n",
              " 300,\n",
              " 59,\n",
              " 42,\n",
              " 41,\n",
              " 149,\n",
              " 22,\n",
              " 31,\n",
              " 30,\n",
              " 155,\n",
              " 47,\n",
              " 25,\n",
              " 80,\n",
              " 22,\n",
              " 115,\n",
              " 56,\n",
              " 102,\n",
              " 118,\n",
              " 221,\n",
              " 204,\n",
              " 114,\n",
              " 156,\n",
              " 39,\n",
              " 36,\n",
              " 48,\n",
              " 77,\n",
              " 60,\n",
              " 168,\n",
              " 51,\n",
              " 22,\n",
              " 152,\n",
              " 75,\n",
              " 30,\n",
              " 95,\n",
              " 24,\n",
              " 49,\n",
              " 35,\n",
              " 29,\n",
              " 106,\n",
              " 66,\n",
              " 159,\n",
              " 48,\n",
              " 162,\n",
              " 24,\n",
              " 136,\n",
              " 248,\n",
              " 25,\n",
              " 27,\n",
              " 37,\n",
              " 68,\n",
              " 150,\n",
              " 24,\n",
              " 80,\n",
              " 157,\n",
              " 25,\n",
              " 73,\n",
              " 89,\n",
              " 58,\n",
              " 36,\n",
              " 76,\n",
              " 47,\n",
              " 104,\n",
              " 38,\n",
              " 69,\n",
              " 22,\n",
              " 119,\n",
              " 94,\n",
              " 70,\n",
              " 73,\n",
              " 42,\n",
              " 17,\n",
              " 13,\n",
              " 45,\n",
              " 57,\n",
              " 105,\n",
              " 162,\n",
              " 47,\n",
              " 115,\n",
              " 158,\n",
              " 79,\n",
              " 142,\n",
              " 62,\n",
              " 71,\n",
              " 175,\n",
              " 29,\n",
              " 29,\n",
              " 148,\n",
              " 83,\n",
              " 37,\n",
              " 44,\n",
              " 45,\n",
              " 161,\n",
              " 50,\n",
              " 298,\n",
              " 159,\n",
              " 125,\n",
              " 51,\n",
              " 28,\n",
              " 34,\n",
              " 46,\n",
              " 81,\n",
              " 28,\n",
              " 90,\n",
              " 18,\n",
              " 54,\n",
              " 55,\n",
              " 45,\n",
              " 146,\n",
              " 40,\n",
              " 107,\n",
              " 50,\n",
              " 120,\n",
              " 160,\n",
              " 32,\n",
              " 34,\n",
              " 32,\n",
              " 16,\n",
              " 67,\n",
              " 55,\n",
              " 43,\n",
              " 23,\n",
              " 149,\n",
              " 20,\n",
              " 23,\n",
              " 40,\n",
              " 169,\n",
              " 117,\n",
              " 62,\n",
              " 166,\n",
              " 24,\n",
              " 136,\n",
              " 99,\n",
              " 45,\n",
              " 23,\n",
              " 25,\n",
              " 147,\n",
              " 26,\n",
              " 146,\n",
              " 89,\n",
              " 168,\n",
              " 117,\n",
              " 46,\n",
              " 26,\n",
              " 28,\n",
              " 32,\n",
              " 144,\n",
              " 57,\n",
              " 158,\n",
              " 42,\n",
              " 111,\n",
              " 36,\n",
              " 146,\n",
              " 50,\n",
              " 33,\n",
              " 15,\n",
              " 177,\n",
              " 160,\n",
              " 63,\n",
              " 84,\n",
              " 84,\n",
              " 57,\n",
              " 96,\n",
              " 169,\n",
              " 76,\n",
              " 47,\n",
              " 130,\n",
              " 23,\n",
              " 149,\n",
              " 32,\n",
              " 22,\n",
              " 101,\n",
              " 281,\n",
              " 54,\n",
              " 120,\n",
              " 138,\n",
              " 127,\n",
              " 66,\n",
              " 40,\n",
              " 40,\n",
              " 70,\n",
              " 160,\n",
              " 26,\n",
              " 32,\n",
              " 51,\n",
              " 159,\n",
              " 146,\n",
              " 103,\n",
              " 45,\n",
              " 142,\n",
              " 92,\n",
              " 26,\n",
              " 134,\n",
              " 37,\n",
              " 22,\n",
              " 22,\n",
              " 33,\n",
              " 69,\n",
              " 109,\n",
              " 35,\n",
              " 99,\n",
              " 140,\n",
              " 50,\n",
              " 46,\n",
              " 149,\n",
              " 63,\n",
              " 95,\n",
              " 69,\n",
              " 110,\n",
              " 51,\n",
              " 27,\n",
              " 34,\n",
              " 126,\n",
              " 142,\n",
              " 148,\n",
              " 24,\n",
              " 147,\n",
              " 24,\n",
              " 29,\n",
              " 86,\n",
              " 87,\n",
              " 38,\n",
              " 104,\n",
              " 59,\n",
              " 38,\n",
              " 38,\n",
              " 22,\n",
              " 25,\n",
              " 135,\n",
              " 87,\n",
              " 19,\n",
              " 66,\n",
              " 140,\n",
              " 156,\n",
              " 22,\n",
              " 107,\n",
              " 65,\n",
              " 145,\n",
              " 137,\n",
              " 25,\n",
              " 59,\n",
              " 103,\n",
              " 37,\n",
              " 58,\n",
              " 87,\n",
              " 58,\n",
              " 123,\n",
              " 67,\n",
              " 66,\n",
              " 102,\n",
              " 130,\n",
              " 148,\n",
              " 35,\n",
              " 8,\n",
              " 62,\n",
              " 56,\n",
              " 143,\n",
              " 20,\n",
              " 100,\n",
              " 49,\n",
              " 36,\n",
              " 53,\n",
              " 88,\n",
              " 133,\n",
              " 36,\n",
              " 37,\n",
              " 123,\n",
              " 92,\n",
              " 80,\n",
              " 136,\n",
              " 35,\n",
              " 97,\n",
              " 66,\n",
              " 119,\n",
              " 65,\n",
              " 26,\n",
              " 28,\n",
              " 45,\n",
              " 157,\n",
              " 36,\n",
              " 94,\n",
              " 59,\n",
              " 140,\n",
              " 22,\n",
              " 56,\n",
              " 43,\n",
              " 61,\n",
              " 56,\n",
              " 54,\n",
              " 37,\n",
              " 25,\n",
              " 21,\n",
              " 36,\n",
              " 93,\n",
              " 153,\n",
              " 153,\n",
              " 46,\n",
              " 34,\n",
              " 80,\n",
              " 69,\n",
              " 24,\n",
              " 108,\n",
              " 46,\n",
              " 29,\n",
              " 22,\n",
              " 158,\n",
              " 86,\n",
              " 30,\n",
              " 143,\n",
              " 169,\n",
              " 42,\n",
              " 111,\n",
              " 18,\n",
              " 109,\n",
              " 76,\n",
              " 73,\n",
              " 92,\n",
              " 36,\n",
              " 54,\n",
              " 76,\n",
              " 29,\n",
              " 40,\n",
              " 28,\n",
              " 22,\n",
              " 77,\n",
              " 109,\n",
              " 75,\n",
              " 76,\n",
              " 30,\n",
              " 49,\n",
              " 155,\n",
              " 160,\n",
              " 316,\n",
              " 195,\n",
              " 37,\n",
              " 125,\n",
              " 48,\n",
              " 39,\n",
              " 161,\n",
              " 121,\n",
              " 145,\n",
              " 162,\n",
              " 29,\n",
              " 38,\n",
              " 25,\n",
              " 40,\n",
              " 226,\n",
              " 70,\n",
              " 140,\n",
              " 47,\n",
              " 63,\n",
              " 17,\n",
              " 101,\n",
              " 41,\n",
              " 80,\n",
              " 137,\n",
              " 103,\n",
              " 29,\n",
              " 51,\n",
              " 148,\n",
              " 25,\n",
              " 149,\n",
              " 38,\n",
              " 62,\n",
              " 179,\n",
              " 34,\n",
              " 47,\n",
              " 40,\n",
              " 110,\n",
              " 131,\n",
              " 101,\n",
              " 42,\n",
              " 102,\n",
              " 65,\n",
              " 27,\n",
              " 31,\n",
              " 82,\n",
              " 23,\n",
              " 59,\n",
              " 133,\n",
              " 33,\n",
              " 95,\n",
              " 95,\n",
              " 135,\n",
              " 159,\n",
              " 151,\n",
              " 73,\n",
              " 149,\n",
              " 103,\n",
              " 22,\n",
              " 51,\n",
              " 137,\n",
              " 58,\n",
              " 89,\n",
              " 81,\n",
              " 57,\n",
              " 26,\n",
              " 32,\n",
              " 145,\n",
              " 118,\n",
              " 143,\n",
              " 23,\n",
              " 136,\n",
              " 94,\n",
              " 8,\n",
              " 99,\n",
              " 65,\n",
              " 71,\n",
              " 117,\n",
              " 129,\n",
              " 157,\n",
              " 28,\n",
              " 150,\n",
              " 31,\n",
              " 71,\n",
              " 70,\n",
              " 94,\n",
              " 48,\n",
              " 160,\n",
              " 94,\n",
              " 31,\n",
              " 39,\n",
              " 152,\n",
              " 71,\n",
              " 162,\n",
              " 141,\n",
              " 25,\n",
              " 22,\n",
              " 48,\n",
              " 33,\n",
              " 44,\n",
              " 47,\n",
              " 26,\n",
              " 112,\n",
              " 148,\n",
              " 19,\n",
              " 133,\n",
              " 48,\n",
              " 107,\n",
              " 38,\n",
              " 27,\n",
              " 124,\n",
              " 131,\n",
              " 23,\n",
              " 156,\n",
              " 161,\n",
              " 25,\n",
              " 42,\n",
              " 27,\n",
              " 22,\n",
              " 98,\n",
              " 89,\n",
              " 147,\n",
              " 129,\n",
              " 152,\n",
              " 215,\n",
              " 26,\n",
              " 66,\n",
              " 149,\n",
              " 372,\n",
              " 155,\n",
              " 160,\n",
              " 81,\n",
              " 73,\n",
              " 76,\n",
              " 153,\n",
              " 24,\n",
              " 231,\n",
              " 87,\n",
              " 72,\n",
              " 105,\n",
              " 158,\n",
              " 54,\n",
              " 58,\n",
              " 54,\n",
              " 114,\n",
              " 88,\n",
              " 144,\n",
              " 29,\n",
              " 136,\n",
              " 23,\n",
              " 39,\n",
              " 35,\n",
              " 24,\n",
              " 95,\n",
              " 73,\n",
              " 45,\n",
              " 160,\n",
              " 159,\n",
              " 149,\n",
              " 134,\n",
              " 154,\n",
              " 92,\n",
              " 102,\n",
              " 31,\n",
              " 77,\n",
              " 139,\n",
              " 156,\n",
              " 44,\n",
              " 136,\n",
              " 132,\n",
              " 143,\n",
              " 127,\n",
              " 276,\n",
              " 78,\n",
              " 27,\n",
              " 79,\n",
              " 24,\n",
              " 52,\n",
              " 68,\n",
              " 24,\n",
              " 44,\n",
              " 24,\n",
              " 55,\n",
              " 62,\n",
              " 104,\n",
              " 87,\n",
              " 148,\n",
              " 49,\n",
              " 154,\n",
              " 56,\n",
              " 158,\n",
              " 126,\n",
              " 43,\n",
              " 77,\n",
              " 49,\n",
              " 84,\n",
              " 49,\n",
              " 162,\n",
              " 79,\n",
              " 31,\n",
              " 155,\n",
              " 146,\n",
              " 23,\n",
              " 160,\n",
              " 62,\n",
              " 39,\n",
              " 67,\n",
              " 73,\n",
              " 148,\n",
              " 88,\n",
              " 37,\n",
              " 23,\n",
              " 56,\n",
              " 53,\n",
              " 73,\n",
              " 80,\n",
              " 44,\n",
              " 92,\n",
              " 35,\n",
              " 23,\n",
              " 139,\n",
              " 106,\n",
              " 103,\n",
              " 34,\n",
              " 77,\n",
              " 158,\n",
              " 26,\n",
              " 47,\n",
              " 24,\n",
              " 148,\n",
              " 133,\n",
              " 126,\n",
              " 78,\n",
              " 132,\n",
              " 116,\n",
              " 221,\n",
              " 59,\n",
              " 137,\n",
              " 143,\n",
              " 24,\n",
              " 38,\n",
              " 42,\n",
              " 24,\n",
              " 157,\n",
              " 47,\n",
              " 41,\n",
              " 122,\n",
              " 126,\n",
              " 26,\n",
              " 114,\n",
              " 7,\n",
              " 34,\n",
              " 156,\n",
              " 92,\n",
              " 90,\n",
              " 22,\n",
              " 85,\n",
              " 63,\n",
              " 220,\n",
              " 41,\n",
              " 60,\n",
              " 88,\n",
              " 31,\n",
              " 37,\n",
              " 28,\n",
              " 24,\n",
              " 118,\n",
              " 22,\n",
              " 210,\n",
              " 50,\n",
              " 49,\n",
              " 87,\n",
              " 61,\n",
              " 141,\n",
              " 54,\n",
              " 28,\n",
              " 49,\n",
              " 53,\n",
              " 145,\n",
              " 160,\n",
              " 53,\n",
              " 12,\n",
              " 142,\n",
              " 71,\n",
              " 129,\n",
              " 33,\n",
              " 47,\n",
              " 72,\n",
              " 148,\n",
              " 104,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyWW8So55Zja"
      },
      "source": [
        "#Adding Length column to the dataframe\n",
        "messages['Length']=length"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "tOj11Vg75Zjb",
        "outputId": "0208ea3a-9f78-4ef8-8ef3-4df1800b6214"
      },
      "source": [
        "messages.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message  Length\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
              "1   ham                      Ok lar... Joking wif u oni...      29\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
              "3   ham  U dun say so early hor... U c already then say...      49\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOeyusCC5Zjb"
      },
      "source": [
        "**Calculating Punctuations in each message**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZB-F6tY5Zjb"
      },
      "source": [
        "#Calculating Punctuations in each message\n",
        "\n",
        "import string\n",
        "count=0\n",
        "punct=[]\n",
        "for i in range(len(messages)):\n",
        "    for j in messages['Message'][i]:\n",
        "        if j in string.punctuation:\n",
        "            count+=1\n",
        "    #print(count)\n",
        "    punct.append(count)\n",
        "    count=0\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2RcWBr05Zjb",
        "outputId": "c9080901-9b6c-4c43-fa31-9a5cb327268d"
      },
      "source": [
        "punct"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 6,\n",
              " 6,\n",
              " 2,\n",
              " 6,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 2,\n",
              " 11,\n",
              " 6,\n",
              " 5,\n",
              " 1,\n",
              " 8,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 7,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 4,\n",
              " 4,\n",
              " 7,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 7,\n",
              " 3,\n",
              " 15,\n",
              " 5,\n",
              " 1,\n",
              " 10,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 7,\n",
              " 2,\n",
              " 11,\n",
              " 1,\n",
              " 14,\n",
              " 5,\n",
              " 6,\n",
              " 12,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 8,\n",
              " 10,\n",
              " 5,\n",
              " 1,\n",
              " 9,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 8,\n",
              " 3,\n",
              " 1,\n",
              " 7,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 6,\n",
              " 8,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 4,\n",
              " 6,\n",
              " 15,\n",
              " 13,\n",
              " 7,\n",
              " 4,\n",
              " 6,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 9,\n",
              " 1,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 5,\n",
              " 8,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 4,\n",
              " 12,\n",
              " 2,\n",
              " 2,\n",
              " 9,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 6,\n",
              " 16,\n",
              " 1,\n",
              " 4,\n",
              " 8,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 5,\n",
              " 5,\n",
              " 13,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 12,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 1,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 5,\n",
              " 5,\n",
              " 8,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 5,\n",
              " 8,\n",
              " 5,\n",
              " 0,\n",
              " 16,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 13,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 7,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 11,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 12,\n",
              " 0,\n",
              " 7,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 8,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 14,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 5,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 11,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 7,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 12,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 14,\n",
              " 7,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 8,\n",
              " 1,\n",
              " 11,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 15,\n",
              " 9,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 3,\n",
              " 10,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 4,\n",
              " 14,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 4,\n",
              " 2,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 7,\n",
              " 4,\n",
              " 1,\n",
              " 8,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 7,\n",
              " 1,\n",
              " 7,\n",
              " 7,\n",
              " 3,\n",
              " 9,\n",
              " 10,\n",
              " 5,\n",
              " 7,\n",
              " 2,\n",
              " 1,\n",
              " 5,\n",
              " 8,\n",
              " 2,\n",
              " 11,\n",
              " 6,\n",
              " 2,\n",
              " 2,\n",
              " 9,\n",
              " 2,\n",
              " 8,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 14,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 6,\n",
              " 11,\n",
              " 11,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 9,\n",
              " 0,\n",
              " 0,\n",
              " 12,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 30,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 17,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 9,\n",
              " 17,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 9,\n",
              " 2,\n",
              " 4,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 4,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 2,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 0,\n",
              " 11,\n",
              " 2,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 18,\n",
              " 7,\n",
              " 10,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 12,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 5,\n",
              " 7,\n",
              " 5,\n",
              " 2,\n",
              " 12,\n",
              " 2,\n",
              " 12,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 4,\n",
              " 7,\n",
              " 3,\n",
              " 7,\n",
              " 5,\n",
              " 5,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 10,\n",
              " 4,\n",
              " 10,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 8,\n",
              " 7,\n",
              " 7,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 6,\n",
              " 15,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 7,\n",
              " 4,\n",
              " 9,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 19,\n",
              " 5,\n",
              " 4,\n",
              " 3,\n",
              " 6,\n",
              " 16,\n",
              " 2,\n",
              " 2,\n",
              " 7,\n",
              " 3,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 12,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 11,\n",
              " 7,\n",
              " 9,\n",
              " 1,\n",
              " 9,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 8,\n",
              " 0,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 9,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 13,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 7,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 8,\n",
              " 2,\n",
              " 9,\n",
              " 2,\n",
              " 11,\n",
              " 4,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 4,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 11,\n",
              " 2,\n",
              " 6,\n",
              " 9,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 10,\n",
              " 3,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 4,\n",
              " 8,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 2,\n",
              " 1,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 7,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 23,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 7,\n",
              " 9,\n",
              " 2,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 10,\n",
              " 5,\n",
              " 13,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 9,\n",
              " 1,\n",
              " 7,\n",
              " 2,\n",
              " 4,\n",
              " 7,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 12,\n",
              " 4,\n",
              " 5,\n",
              " 10,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 12,\n",
              " 11,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 11,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 8,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 9,\n",
              " 7,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 10,\n",
              " 4,\n",
              " 3,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 9,\n",
              " 0,\n",
              " 10,\n",
              " 5,\n",
              " 1,\n",
              " 10,\n",
              " 2,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 6,\n",
              " 1,\n",
              " 13,\n",
              " 8,\n",
              " 2,\n",
              " 14,\n",
              " 0,\n",
              " 13,\n",
              " 0,\n",
              " 7,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 6,\n",
              " 4,\n",
              " 10,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 10,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 9,\n",
              " 4,\n",
              " 4,\n",
              " 2,\n",
              " 8,\n",
              " 1,\n",
              " 3,\n",
              " 19,\n",
              " 7,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 9,\n",
              " 9,\n",
              " 5,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 4,\n",
              " 7,\n",
              " 5,\n",
              " 7,\n",
              " 8,\n",
              " 1,\n",
              " 7,\n",
              " 4,\n",
              " 8,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 0,\n",
              " 11,\n",
              " 4,\n",
              " 1,\n",
              " 11,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 11,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " 8,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 8,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 4,\n",
              " 8,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 6,\n",
              " 9,\n",
              " 1,\n",
              " 0,\n",
              " 13,\n",
              " 7,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 8,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 9,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 7,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 9,\n",
              " 13,\n",
              " 12,\n",
              " 3,\n",
              " 0,\n",
              " 4,\n",
              " 9,\n",
              " 11,\n",
              " 4,\n",
              " 7,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stC14FOa5Zjc"
      },
      "source": [
        "#Adding punctuation length column to dataframe\n",
        "messages[\"Punctuation\"]=punct"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoqjug4O5Zjc"
      },
      "source": [
        "<br>\n",
        "\n",
        "### 3.1 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVIex2EV5Zjc",
        "outputId": "4b3c992c-628e-4393-dbb0-0ec9de50399d"
      },
      "source": [
        "#Regex\n",
        "import re\n",
        "\n",
        "#Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#Creating object for Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ7W9uis5Zjc"
      },
      "source": [
        "#Removal of extra characters and stop words and lemmatization\n",
        "corpus = []\n",
        "\n",
        "#Skipping the 0th index (it's of Label)\n",
        "for i in range(0,len(messages)):\n",
        "    words = re.sub('[^a-zA-Z]',' ',messages['Message'][i])\n",
        "    words = words.lower()\n",
        "    #Splits into list of words \n",
        "    words = words.split()\n",
        "    \n",
        "    #Lemmatizing the word and removing the stopwords\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "    \n",
        "    #Again join words to form sentences\n",
        "    words = ' '.join(words)\n",
        "    \n",
        "    corpus.append(words)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gFLbHpdp5Zjc",
        "outputId": "ef594988-44ef-4d87-c5e5-a7e0292183b4"
      },
      "source": [
        "#What's in Corpus\n",
        "corpus[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YxERp96c5Zjd",
        "outputId": "3fd7a4a5-9374-4e62-998c-69e3a47ed412"
      },
      "source": [
        "corpus[1]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ok lar joking wif u oni'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmNbczhF5Zjd"
      },
      "source": [
        "#Replacing Original Message with the Transformed Messages\n",
        "messages['Message'] = corpus"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Z6ovYsqK5Zjd",
        "outputId": "44b56f7f-68d2-4efd-d940-ab8b3a80a51e"
      },
      "source": [
        "messages.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "      <td>111</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
              "      <td>155</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah think go usf life around though</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message  Length  Punctuation\n",
              "0   ham  go jurong point crazy available bugis n great ...     111            9\n",
              "1   ham                            ok lar joking wif u oni      29            6\n",
              "2  spam  free entry wkly comp win fa cup final tkts st ...     155            6\n",
              "3   ham                u dun say early hor u c already say      49            6\n",
              "4   ham                nah think go usf life around though      61            2"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xm5Qmlt5Zjd"
      },
      "source": [
        "<br>\n",
        "\n",
        "### 3.2 Analyzing the difference between Spam and Ham messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ZJg29r5Zjd"
      },
      "source": [
        "spam_messages = messages[messages['Label'] == 'spam']\n",
        "ham_messages = messages[messages['Label'] == 'ham']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "jyM-_IMq5Zje",
        "outputId": "dcb095b2-e87d-4263-b96d-74ce638681a4"
      },
      "source": [
        "spam_messages.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
              "      <td>155</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>freemsg hey darling week word back like fun st...</td>\n",
              "      <td>147</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>winner valued network customer selected receiv...</td>\n",
              "      <td>157</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>mobile month u r entitled update latest colour...</td>\n",
              "      <td>154</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>spam</td>\n",
              "      <td>six chance win cash pound txt csh send cost p ...</td>\n",
              "      <td>136</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label  ... Punctuation\n",
              "2   spam  ...           6\n",
              "5   spam  ...           8\n",
              "8   spam  ...           6\n",
              "9   spam  ...           2\n",
              "11  spam  ...           8\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "-p2SHCXn5Zje",
        "outputId": "9b03d3d5-659f-4861-ed16-6f9327fbf004"
      },
      "source": [
        "ham_messages.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "      <td>111</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah think go usf life around though</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>even brother like speak treat like aid patent</td>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message  Length  Punctuation\n",
              "0   ham  go jurong point crazy available bugis n great ...     111            9\n",
              "1   ham                            ok lar joking wif u oni      29            6\n",
              "3   ham                u dun say early hor u c already say      49            6\n",
              "4   ham                nah think go usf life around though      61            2\n",
              "6   ham      even brother like speak treat like aid patent      77            2"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ZycOG65Zje",
        "outputId": "f84e9115-f74d-40e2-d1b4-57b73ef7f98d"
      },
      "source": [
        "spam_messages['Length'].mean()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138.6706827309237"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc1Z0F3m5Zje",
        "outputId": "14acf492-9ef1-45ea-c817-923345c8589e"
      },
      "source": [
        "ham_messages['Length'].mean()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.48248704663213"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh5ApEg05Zje"
      },
      "source": [
        "We can see that Spam messages have more average words than Ham messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwTElUPi5Zje",
        "outputId": "987cb042-6521-42ea-c413-838b27f1ebe0"
      },
      "source": [
        "spam_messages['Punctuation'].mean()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.712182061579652"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0P_mGAJ5Zje",
        "outputId": "63a6bb0f-996a-4acb-cbc6-3fb6030931ab"
      },
      "source": [
        "ham_messages['Punctuation'].mean()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.9398963730569947"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TwtZRsN5Zjf"
      },
      "source": [
        "Same with Punctuation also, We can see that Spam messages have more average punctuation than Ham messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBYE2L8L5Zjf"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9hSe5875Zjf"
      },
      "source": [
        "## 4.0 Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR29duKe5Zjf"
      },
      "source": [
        "X = messages['Message']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz1hmf5t5Zjf",
        "outputId": "9756d6db-ea1c-4a08-c819-d9529f3671e2"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    go jurong point crazy available bugis n great ...\n",
              "1                              ok lar joking wif u oni\n",
              "2    free entry wkly comp win fa cup final tkts st ...\n",
              "3                  u dun say early hor u c already say\n",
              "4                  nah think go usf life around though\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU0hDKM55Zjf"
      },
      "source": [
        "y = messages['Label']"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snifctr95Zjf",
        "outputId": "02fa9551-5a4d-4923-d10a-1beafb72d8ba"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     ham\n",
              "1     ham\n",
              "2    spam\n",
              "3     ham\n",
              "4     ham\n",
              "Name: Label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k6Jpp-25Zjf"
      },
      "source": [
        "### 4.1 Train Test Split - Split the data into 77% (training data) and 33% (test data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpH06bFt5Zjg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbESlMyB5Zjg"
      },
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X , y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSNH19qp5Zjg",
        "outputId": "b45abe85-c7b7-4148-d4c4-c20d61a7714d"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3235                                            yup comin\n",
              "945     sent score sophas secondary application school...\n",
              "5319                              kothi print marandratha\n",
              "5528                             effect irritation ignore\n",
              "247                                         asked call ok\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191rIQkf5Zjg",
        "outputId": "fa243cbb-9236-4f0e-df8c-faf58bd1eefd"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3245    squeeeeeze christmas hug u lik frndshp den hug...\n",
              "944     also sorta blown couple time recently id rathe...\n",
              "1044    mmm thats better got roast b better drink good...\n",
              "2484                  mm kanji dont eat anything heavy ok\n",
              "812     ring come guy costume gift future yowifes hint...\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-uzpNIp5Zjg"
      },
      "source": [
        "### 4.2 Demonstration of Count Vectorizer\n",
        "\n",
        "(Bag of Words)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I_yo0Qb5Zjg"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XN7WQ655Zjg"
      },
      "source": [
        "count_vect=CountVectorizer()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK5g3Ar25Zjg"
      },
      "source": [
        "X_train_count_vect=count_vect.fit_transform(X_train).toarray()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7ZIp81D5Zjg",
        "outputId": "096b3450-ad2b-4504-92eb-4b53fb491797"
      },
      "source": [
        "X_train_count_vect"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW1TrAag5Zjh",
        "outputId": "fe1536b8-46d3-4daf-9dc9-139df12814a9"
      },
      "source": [
        "# 3733 are the sentences and 5772 are the words in total sentences\n",
        "X_train_count_vect.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 5772)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iJC0h9A5Zjh"
      },
      "source": [
        "**Note:-**<br>\n",
        "There might be that, some words in 5772 words are not frequently present and are just appearing 1-2 times, we can reduce them using cv = CountVectorizer(max_features = 4000) (an approach)\n",
        "\n",
        "This will only take 4000 words leading to coming of most frequent words\n",
        "\n",
        "    We can change the max_features, according to what we want"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCLGylB75Zji"
      },
      "source": [
        "### 4.3 Demonstration of TF-IDF Vectorizer\n",
        "\n",
        "(Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "\n",
        "CountVectorizer(Bag of Words) + TFIDF Transformer, Scikit-Learn has provided with a method of TFIDF vectorizer (combining two steps into one)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_DNKqju5Zjj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6nBuN9S5Zjj"
      },
      "source": [
        "tfidf=TfidfVectorizer()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmC-_JBr5Zjj"
      },
      "source": [
        "X_train_tfidf_vect=count_vect.fit_transform(X_train).toarray()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcRW8sLO5Zjj",
        "outputId": "54e7a7ef-1a4e-4069-c1f5-e6013530823f"
      },
      "source": [
        "X_train_tfidf_vect"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxwpt3LD5Zjj",
        "outputId": "7b87b427-6e4d-49f8-c8e9-fdc9d1b8c0c1"
      },
      "source": [
        "X_train_tfidf_vect.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 5772)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYb2hWV05Zjj"
      },
      "source": [
        "# 5.0 Model Building\n",
        "\n",
        "We are doing pipelining as we need to perform the same procedures for the test data to get predictions, that may be tiresome.\n",
        "\n",
        "However what convenient about this pipeline object is that it actually can perform all these steps for you in a single cell, that means you can directly provide the data and it will be both vectorized and run the classifier on it in a single step.\n",
        "\n",
        "Pipeline takes list of tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdZ9xf65Zjj"
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyZXjaBV5Zjk"
      },
      "source": [
        "### Naive Bayer Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h7xIDkz5Zjk"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJj_VGK5Zjk"
      },
      "source": [
        "#each tuple takes the name you decide , next you call what you want to occur\n",
        "text_mnb=Pipeline([('tfidf',TfidfVectorizer()),('mnb',MultinomialNB())])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnF4ns735Zjk",
        "outputId": "592f1568-5ddf-45c4-ed92-830fdeb7a0fd"
      },
      "source": [
        "#Now u can directly pass the X_train dataset.\n",
        "text_mnb.fit(X_train,y_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('mnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shDzRB1F5Zjk",
        "outputId": "8529966a-227a-459a-fd60-9e44f9bc1a8d"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3245    squeeeeeze christmas hug u lik frndshp den hug...\n",
              "944     also sorta blown couple time recently id rathe...\n",
              "1044    mmm thats better got roast b better drink good...\n",
              "2484                  mm kanji dont eat anything heavy ok\n",
              "812     ring come guy costume gift future yowifes hint...\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3aceRT5Zjk"
      },
      "source": [
        "#It will take the X_test and do all the steps, vectorize it and predict it\n",
        "y_preds_mnb=text_mnb.predict(X_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWeOAVkW5Zjk",
        "outputId": "22fee0e2-ca21-4870-987e-a8681fef4032"
      },
      "source": [
        "#Predictions of the test data\n",
        "y_preds_mnb"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITnjIcvS5Zjl",
        "outputId": "d9c07e57-986b-4f35-c15e-42e4fb4fdc93"
      },
      "source": [
        "#Training score\n",
        "text_mnb.score(X_train,y_train)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975622823466381"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z-_p9Ba5Zjl",
        "outputId": "50a99b71-c0ae-43e6-e6db-5cf19019788d"
      },
      "source": [
        "#Testing score\n",
        "text_mnb.score(X_test,y_test)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9700924415443176"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM_aVnnf5Zjl"
      },
      "source": [
        "**Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5NEUh3F5Zjl"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFUeGAo95Zjl",
        "outputId": "e03a3bf3-842e-463a-c9a5-a07714d0733a"
      },
      "source": [
        "print(confusion_matrix(y_test,y_preds_mnb))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1592    1]\n",
            " [  54  192]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGyKsBhW5Zjl"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVVrqK8x5Zjl",
        "outputId": "6e5a5446-db37-4cfb-d454-c15a143995bc"
      },
      "source": [
        "print(classification_report(y_test,y_preds_mnb))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98      1593\n",
            "        spam       0.99      0.78      0.87       246\n",
            "\n",
            "    accuracy                           0.97      1839\n",
            "   macro avg       0.98      0.89      0.93      1839\n",
            "weighted avg       0.97      0.97      0.97      1839\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0qmpS8y5Zjl"
      },
      "source": [
        "### The above shows that “ham” label got predicted good but “spam” label prediction is not fine , so we can’t say that model is excellent. Model is lacking in predicting spam accurately. We may try the same problem with SVM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLrykHEA5Zjm"
      },
      "source": [
        "### Prediciting on New SMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkyYUX1X5Zjm"
      },
      "source": [
        "text = 'Congratulations, you have won a lottery of $5000. To Won Text on,555500 '"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjwx1hrR5Zjm"
      },
      "source": [
        "def refined_text(text):\n",
        "    #Removal of extra characters and stop words\n",
        "    words = re.sub('[^a-zA-Z]',' ',text)\n",
        "    words = words.lower()\n",
        "    #Splits into list of words \n",
        "    words = words.split()\n",
        "\n",
        "    #Lemmatizing the word and removing the stopwords\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "\n",
        "    #Again join words to form sentences\n",
        "    words = ' '.join(words)\n",
        "    return words"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g82qaVWC5Zjm"
      },
      "source": [
        "refined_word = refined_text(text)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msu4jwuj5Zjm"
      },
      "source": [
        "refined_word = [refined_word]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfa7VJ9n5Zjm",
        "outputId": "f6563162-deac-4bf3-984e-1c1170ae62be"
      },
      "source": [
        "refined_word"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['congratulation lottery text']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPfJCjtV5Zjm",
        "outputId": "84840101-eb6d-4947-863b-df50ce452457"
      },
      "source": [
        "# Directly predicting the single message to the model\n",
        "text_mnb.predict(refined_word)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['spam'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbxSaM95Zjn"
      },
      "source": [
        "### SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ZSy2Mz5Zjn"
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8zpWxYO5Zjn"
      },
      "source": [
        "#each tuple takes the name you decide , next you call what you want to occur\n",
        "text_svm=Pipeline([('tfidf',TfidfVectorizer()),('svm',LinearSVC())])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxo4eAqq5Zjn",
        "outputId": "c2a0f58a-f5c5-4acb-833f-23e49c0e1796"
      },
      "source": [
        "#Now u can directly pass the X_train dataset.\n",
        "text_svm.fit(X_train,y_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('svm',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRrzJGtJ5Zjn",
        "outputId": "26f54ff6-7492-4c6e-9368-82d59b759744"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3245    squeeeeeze christmas hug u lik frndshp den hug...\n",
              "944     also sorta blown couple time recently id rathe...\n",
              "1044    mmm thats better got roast b better drink good...\n",
              "2484                  mm kanji dont eat anything heavy ok\n",
              "812     ring come guy costume gift future yowifes hint...\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ScCRDC5Zjn"
      },
      "source": [
        "#It will take the X_test and do all the steps, vectorize it and predict it\n",
        "y_preds_svm=text_svm.predict(X_test)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpbRQZ465Zjo",
        "outputId": "13ac8bb7-d7f9-446d-c99c-e0434b45d5e5"
      },
      "source": [
        "#Predictions of the test data\n",
        "y_preds_svm"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4OZjP2o5Zjo",
        "outputId": "afc8dce8-4f94-4fbe-eece-3e3a85b7301f"
      },
      "source": [
        "#Training score\n",
        "text_svm.score(X_train,y_train)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnUiPER55Zjo",
        "outputId": "dec054be-0335-4ba7-bc76-b0ca5cad31e0"
      },
      "source": [
        "#Testing score\n",
        "text_svm.score(X_test,y_test)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9869494290375204"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_3dudXF5Zjo"
      },
      "source": [
        "**Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opk9AG0w5Zjo"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSQCmJOz5Zjo",
        "outputId": "c46489cd-7888-475b-aab3-2d6b61124bcc"
      },
      "source": [
        "print(confusion_matrix(y_test,y_preds_svm))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1589    4]\n",
            " [  20  226]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYahhZri5Zjo"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37QvyGtN5Zjo",
        "outputId": "062735c8-f15b-4336-b4a4-b434e55e03e6"
      },
      "source": [
        "print(classification_report(y_test,y_preds_svm))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99      1593\n",
            "        spam       0.98      0.92      0.95       246\n",
            "\n",
            "    accuracy                           0.99      1839\n",
            "   macro avg       0.99      0.96      0.97      1839\n",
            "weighted avg       0.99      0.99      0.99      1839\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTaeW7Vw5Zjo"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": []
    }
  ]
}